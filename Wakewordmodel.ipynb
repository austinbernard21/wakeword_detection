{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from os.path import isdir, join\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import IPython\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import python_speech_features\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_time_segment(segment_ms):\n",
    "    \"\"\"\n",
    "    Gets a random time segment of duration segment_ms in a 60,000 ms audio clip.\n",
    "    \n",
    "    Arguments:\n",
    "    segment_ms -- the duration of the audio clip in ms (\"ms\" stands for \"milliseconds\")\n",
    "    \n",
    "    Returns:\n",
    "    segment_time -- a tuple of (segment_start, segment_end) in ms\n",
    "    \"\"\"\n",
    "    \n",
    "    segment_start = np.random.randint(low=0, high=10000-segment_ms)   # Make sure segment doesn't run past the 10sec background \n",
    "    segment_end = segment_start + segment_ms -1\n",
    "    \n",
    "    return (segment_start, segment_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "background = AudioSegment.from_wav('audio/Recording (70) (online-audio-converter.com).wav')\n",
    "audio_clip = AudioSegment.from_wav('audio/test_rillakuma.wav')\n",
    "segment_start, segment_end = get_random_time_segment(2000)\n",
    "\n",
    "temp_file_name = 'insert_clip.wav'\n",
    "new_clip = background.overlay(audio_clip,position=segment_start)\n",
    "new_clip[segment_start:segment_end].export(temp_file_name, format=\"wav\")\n",
    "IPython.display.Audio(temp_file_name)\n",
    "\n",
    "\n",
    "signal, rate = librosa.load(temp_file_name, sr=8000)\n",
    "mfcc = python_speech_features.base.mfcc(signal, samplerate=rate, winstep=0.15, winlen=.2, nfft=2048, winfunc=np.hamming)\n",
    "dim_1, dim_2 = mfcc.shape\n",
    "fig = plt.figure()\n",
    "plt.imshow(mfcc, cmap='inferno', origin='lower', aspect='auto')\n",
    "reshape_dim = dim_1 * dim_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_files = []\n",
    "for i in range(int(len(background) / 10000)):\n",
    "    t = i * 10000\n",
    "    newAudio = background[t:t+10000]\n",
    "    newAudio.export(f'audio/background/background_{i}.wav', format=\"wav\")\n",
    "    background_files.append(f'audio/background/background_{i}.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample(background, audio_clip):\n",
    "    segment_start, segment_end = get_random_time_segment(2000)\n",
    "\n",
    "    temp_file_name = 'insert_clip.wav'\n",
    "    new_clip = background.overlay(audio_clip,position=segment_start)\n",
    "    new_clip[segment_start:segment_end].export(temp_file_name, format=\"wav\")\n",
    "\n",
    "    signal, rate = librosa.load(temp_file_name, sr=8000)\n",
    "    mfcc = python_speech_features.base.mfcc(signal, samplerate=rate, winstep=0.15, winlen=.2, nfft=2048, winfunc=np.hamming)\n",
    "\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('signal shapesignal.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_speech_path = 'audio/google_speech'\n",
    "pos_sample_path = 'audio/train'\n",
    "\n",
    "positive_samples = []\n",
    "for file in os.listdir(pos_sample_path):\n",
    "    audio_clip = AudioSegment.from_wav(join(pos_sample_path,file))\n",
    "    background = AudioSegment.from_wav(rand.choice(background_files))\n",
    "    positive_samples.append(create_sample(background,audio_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 13, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(positive_samples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_file_names = []\n",
    "for name in os.listdir(google_speech_path):\n",
    "    if isdir(join(google_speech_path, name)):\n",
    "        negative_file_names.append(name)\n",
    "        \n",
    "negative_file_names = negative_file_names[:-1]\n",
    "\n",
    "negative_samples = []\n",
    "for name in negative_file_names:\n",
    "    filepath = join(google_speech_path, name)\n",
    "    for file in os.listdir(filepath)[:5]:\n",
    "        audio_clip = AudioSegment.from_wav(join(filepath,file))\n",
    "        background = AudioSegment.from_wav(rand.choice(background_files))\n",
    "        negative_samples.append(create_sample(background,audio_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 13, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(negative_samples).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(positive_samples)):\n",
    "    X_train.append(positive_samples[i])\n",
    "    y_train.append(1)\n",
    "\n",
    "for i in range(len(negative_samples)):\n",
    "    X_train.append(negative_samples[i])\n",
    "    y_train.append(0)\n",
    "    \n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thebe\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier()\n",
    "model.fit(np.array(X_train[:-1]).reshape(-1,reshape_dim),np.array(y_train[:-1]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import datasets\n",
    "# data = datasets.load_digits()\n",
    "# data.data.shape\n",
    "# np.array(X_train[:-1]).reshape(-1,325).shape\n",
    "print(model.predict(np.array(X_train[-1]).reshape(-1,reshape_dim)))\n",
    "print(y_train[-1])\n",
    "\n",
    "test_positive = AudioSegment.from_wav('audio/test_rillakuma.wav')\n",
    "test_negative = AudioSegment.from_wav('audio/google_speech/dog/402e2977_nohash_0.wav')\n",
    "test_negative_1 = AudioSegment.from_wav('audio/google_speech/marvin/3c8836dc_nohash_0.wav')\n",
    "pos_test_sample = create_sample(background, test_positive)\n",
    "neg_test_sample_1 = create_sample(background, test_negative)\n",
    "neg_test_sample_2 = create_sample(background, test_negative_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  [1]  label is : 1\n",
      "prediction:  [0]  label is : 0\n",
      "prediction:  [0]  label is : 0\n"
     ]
    }
   ],
   "source": [
    "print('prediction: ', model.predict(np.array(pos_test_sample).reshape(1,reshape_dim)), ' label is : 1' )\n",
    "print('prediction: ', model.predict(np.array(neg_test_sample_1).reshape(1,reshape_dim)), ' label is : 0' )\n",
    "print('prediction: ', model.predict(np.array(neg_test_sample_2).reshape(1,reshape_dim)), ' label is : 0' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990228013029316"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(np.array(X_train).reshape(-1,reshape_dim),np.array(y_train).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(X_train).reshape(-1,reshape_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'audio/test'\n",
    "\n",
    "positive = []\n",
    "for file in os.listdir(path):\n",
    "    audio_clip = AudioSegment.from_wav(join(path,file))\n",
    "    background = AudioSegment.from_wav(rand.choice(background_files))\n",
    "    positive.append(create_sample(background,audio_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = []\n",
    "for name in negative_file_names:\n",
    "    filepath = join(google_speech_path, name)\n",
    "    for file in os.listdir(filepath)[10:12]:\n",
    "        audio_clip = AudioSegment.from_wav(join(filepath,file))\n",
    "        background = AudioSegment.from_wav(rand.choice(background_files))\n",
    "        negative.append(create_sample(background,audio_clip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(sum(model.predict(np.array(positive).reshape(-1,reshape_dim)))/len(positive))\n",
    "print(sum(model.predict(np.array(negative).reshape(-1,reshape_dim)))/len(negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array(positive).reshape(-1,reshape_dim)))\n",
    "print(model.predict(np.array(negative).reshape(-1,reshape_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_neg = rand.choices(negative_sample_files, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_predictions = model.predict(np.array(positive).reshape(-1,reshape_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_preds = [i for i, x in enumerate(synth_predictions) if not x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_files = []\n",
    "for i in false_preds:\n",
    "    bad_files.append(join(path,os.listdir(path)[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['audio/test\\\\Recording (70).wav']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(filename):\n",
    "    # Trim or pad audio segment to 2000ms\n",
    "    padding = AudioSegment.silent(duration=2000)\n",
    "    segment = AudioSegment.from_wav(filename)[:2000]\n",
    "    segment = padding.overlay(segment)\n",
    "    # Set frame rate to 44100\n",
    "    segment = segment.set_frame_rate(44100)\n",
    "    # Export as wav\n",
    "    return segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'audio/test'\n",
    "\n",
    "positive = []\n",
    "for file in os.listdir(path):\n",
    "    temp_file_name = 'insert_clip.wav'\n",
    "    new_clip = preprocess_audio(join(path,file))\n",
    "    new_clip.export(temp_file_name, format=\"wav\")\n",
    "    signal, rate = librosa.load(temp_file_name, sr=8000)\n",
    "    mfcc = python_speech_features.base.mfcc(signal, samplerate=rate, winstep=0.15, winlen=.2, nfft=2048, winfunc=np.hamming)\n",
    "    positive.append(mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array(positive).reshape(-1,reshape_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'initial_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}